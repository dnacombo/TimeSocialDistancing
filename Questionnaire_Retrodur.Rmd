---
title: "Retrospective duration: Duration Estimation"
params:
  ExperimentID: null
output:
  html_notebook:
    code_folding: hide
    toc: yes
  html_document:
    df_print: paged
    code_folding: hide
    toc: yes
editor_options: 
  chunk_output_type: inline
---
<!-- # This is the Blursday database paper source code. -->
<!-- # This code was used to prepare the following article: -->
<!-- # XXX Ref. to add XXX -->
<!-- # -->
<!-- # The live application of the server can be accessed at  -->
<!-- # https://dnacombo.shinyapps.io/Blursday/ -->
<!-- # This code is publicly available at -->
<!-- # https://github.com/dnacombo/TSDshiny -->

<!-- #     Copyright (C) 2021  Maximilien Chaumon -->
<!-- # -->
<!-- #     This program is free software: you can redistribute it and/or modify -->
<!-- #     it under the terms of the GNU General Public License as published by -->
<!-- #     the Free Software Foundation, either version 3 of the License, or -->
<!-- #     (at your option) any later version. -->
<!-- # -->
<!-- #     This program is distributed in the hope that it will be useful, -->
<!-- #     but WITHOUT ANY WARRANTY; without even the implied warranty of -->
<!-- #     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the -->
<!-- #     GNU General Public License for more details. -->
<!-- # -->
<!-- #     You should have received a copy of the GNU General Public License -->
<!-- #     along with this program.  If not, see <http://www.gnu.org/licenses/>. -->

```{r, message=F}
library(tidyverse)
library(ggbeeswarm)
library(flextable)
library(MaxPac)
# library(afex)
library(emmeans)
library(effectsize)
theme_set(theme_minimal())

source('helpers.R')


```

# Reading data

We read data from the `RetroDuration` questionnaire. Translate responses using QTranslate() (google sheet). Read response to the `initial_RetrospectiveDuration` question. Extract estimated duration since last login as `##:##:##` --\> Hours:Minutes:Seconds. Compute `ClockDuration` as the difference between current time and last login.

Compute :

-   EstimatedDuration = Estimated Magnitude = initial_RetrospectiveDuration in seconds
-   ClockDuration = Clock time since last recorded login in seconds
-   rEstimatedDuration = EstimatedDuration / ClockDuration
-   EstimationError = Estmiation Error = EstimatedDuration - ClockDuration
-   rEstimationError = EstimationError / ClockDuration

```{r, message=F}

load(file.path(dirBlursday,'Daily_Login_Times.RData'))

# Extracting data:

RetroDuration <- gimmeRdata(dirBlursday, UniqueName = 'RetroDuration') %>%
  filter(!Country %in% c('UK','CO', 'US')) %>%
  QTranslate() %>%
  filter(Question_Key %in% c('initial_RetrospectiveDuration')) %>%
  mutate(Date = lubridate::date(Local_Date)) %>%
  pivot_wider(id_cols = c('PID', 'Session','Run', 'Country', 'Local_Date'), names_from = Question_Key, values_from = Response) %>%
  # take only the first response if there are several ones
  group_by(PID,Session,Run,Country) %>%
  slice(1) %>%
  add_Demographics() %>%
  # For EstimatedDuration
  # Using 3 AM to change day
  mutate(Date = lubridate::as_date(Local_Date - lubridate::duration(hours = 3))) %>%
  left_join(select(daily_login_times, PID, Session, Local_Date, Date), by = c('PID','Date'), suffix = c('','_First_Login')) %>%
  mutate(Date = lubridate::as_date(Local_Date)) %>%
  mutate(ClockDuration = Local_Date - Local_Date_First_Login) %>%
  select(Country, PID, Session, Run, Local_Date, ClockDuration, initial_RetrospectiveDuration,
         Handedness, Sex, Age, Date) %>%
  mutate(M = str_match(initial_RetrospectiveDuration,
                       '^.*?(\\d+).*?[:：].*?(\\d+).*?[:：].*?(\\d+).*?$'),
         h = suppressWarnings(as.numeric(M[,2])),
         m = suppressWarnings(as.numeric(M[,3])),
         s = suppressWarnings(as.numeric(M[,4])),
         EstimatedDuration = lubridate::duration(hour = h, minute = m, second = s),
         ClockDuration = lubridate::as.duration(ClockDuration),
         rEstimatedDuration = EstimatedDuration / ClockDuration,
         EstimationError = EstimatedDuration - ClockDuration,
         rEstimationError = EstimationError / ClockDuration) %>%
  select(-M) %>% # ,-h,-m,-s
  ungroup()

save(RetroDuration, file = file.path(dirBlursday,'RetroDuration.RData'))

load(file = file.path(dirBlursday,'RetroDuration.RData'))
```

```{r}
RetroDuration %>% 
  mutate(across(c(ClockDuration,EstimatedDuration, EstimationError),as.numeric)) %>%
  skimr::skim()
```

# Outliers detection and clean up

```{r}
RetroDuration %>%
  mutate(across(c(ClockDuration, EstimatedDuration, rEstimatedDuration, rEstimationError), as.numeric)) %>%
  pivot_longer(cols = c(ClockDuration, EstimatedDuration, rEstimatedDuration, rEstimationError)) %>%
ggplot(aes(x = value, fill = Country)) + 
  geom_histogram(bins = 50) +
  facet_wrap(~name ,scales = 'free') +
  ggtitle('Measure distributions')
```

Distributions of `ClockDuration`, `EstimatedDuration`, `rEstimationError`, and `rEstimatedDuration` are highly skewed to the left. First capping EstimatedDuration and ClockDuration to a decent duration, then removing 5% most extreme `rEstimationError`.

Rationale:

-   `ClockDuration` cannot be below 60 s: no questionnaire/task can be completed under this duration, and we want at least one.
-   `ClockDuration` cannot be above 18000 s = 5 h: subjects cannot be focused for 5h in a row.
-   Same rationale for `EstimatedDuration`, but 5 fold more permissive (we allow EstimatedDuration up to 5 \* 18000s, and below 60 / 5 s).
-   5% Largest/smallest `rEstimationError` is systematically discarded. This is done for each Session and Country separately.

We count these

```{r}
# capped_outliers:
Duration_max <- 18000
Duration_min <- 60
Ratio_rejection_ClockDuration_to_EstimatedDuration <- 5
# trim_outliers:
probs <- c(.025, .975)

OutlierStats <- RetroDuration %>%
  group_by(Country,Session) %>%
  filter(!is.na(rEstimatedDuration), rEstimatedDuration != 0) %>%
  mutate(capped_outliers = ClockDuration > Duration_max | ClockDuration < Duration_min | EstimatedDuration > Duration_max * Ratio_rejection_ClockDuration_to_EstimatedDuration | EstimatedDuration < Duration_min / Ratio_rejection_ClockDuration_to_EstimatedDuration,
         ncapped_outliers = sum(capped_outliers, na.rm = T),
         prop_capped_outliers = ncapped_outliers/n()) %>%
  filter(!capped_outliers) %>%
  mutate(trim_outliers = find.outliers(rEstimationError,meth = 'trim', probs = probs),
         ntrim_outliers = sum(trim_outliers, na.rm = T)) %>%
  summarize(prop_trim_outliers = unique(ntrim_outliers)/n(),
            prop_capped_outliers = unique(prop_capped_outliers),
            ntrim_outliers = unique(ntrim_outliers),
            ncapped_outliers = unique(ncapped_outliers))
```


```{r}
OutlierStats %>% group_by() %>%
  summarize(across(starts_with('n'),list(sum = sum,
                                         min = min, 
                                         max = max,
                                         mean = mean,
                                         sd = sd))) %>%
  pivot_longer(starts_with('n')) %>%
  flextable() %>%
  colformat_double(big.mark = " ", digits = 3) 



OutlierStats %>%
  select(-starts_with('prop')) %>%
  pivot_wider(names_from = c(Session), values_from = c(ntrim_outliers, ncapped_outliers)) %>%
  flextable() %>%
  colformat_double(big.mark = " ", digits = 3) %>%
  add_header_lines('Number of outliers per Country x Session')
```


```{r}
OutlierStats %>% group_by() %>%
  summarize(across(starts_with('prop'),list(min = min, 
                                            max = max,
                                            mean = mean,
                                            sd = sd))) %>%
  pivot_longer(starts_with('prop')) %>%
  flextable() %>%
  colformat_double(big.mark = " ", digits = 3) 

OutlierStats %>%
  select(-starts_with('n')) %>%
  pivot_wider(names_from = c(Session), values_from = c(prop_trim_outliers,prop_capped_outliers)) %>%
  flextable() %>%
  colformat_double(big.mark = " ", digits = 3) %>%
  add_header_lines('Proportion of outliers per Country x Session')
```


```{r}
RetroDuration_clean <- RetroDuration %>%
  filter(!is.na(rEstimatedDuration), rEstimatedDuration != 0)
nrowsbefore_outliers <- nrow(RetroDuration_clean)
RetroDuration_clean <- RetroDuration_clean %>%
  group_by(Country,Session) %>%
  mutate(outliers = ClockDuration > Duration_max | ClockDuration < Duration_min | EstimatedDuration > Duration_max * Ratio_rejection_ClockDuration_to_EstimatedDuration | EstimatedDuration < Duration_min / Ratio_rejection_ClockDuration_to_EstimatedDuration) %>%
  filter(!outliers) %>%
  mutate(outliers = find.outliers(rEstimationError,meth = 'trim', probs = probs)) %>%
  filter(!outliers) %>%
  ungroup() %>% select(-outliers)
nrowsafter_outliers <- nrow(RetroDuration_clean)

cat('Global proportion of outliers', prop_outliers_global <- 1 - nrowsafter_outliers / nrowsbefore_outliers)

save(RetroDuration_clean, file = file.path(dirBlursday,'RetroDuration_clean.RData'))

RetroDuration_clean %>%
  group_by(Country,Session) %>%
  mutate(across(c(ClockDuration, EstimatedDuration, rEstimatedDuration, rEstimationError), as.numeric)) %>%
  pivot_longer(cols = c(ClockDuration, EstimatedDuration, rEstimatedDuration, rEstimationError)) %>%
ggplot(aes(x = value, fill = Country)) + 
  geom_histogram(bins = 50) +
  facet_wrap(~name ,scales = 'free')
```

```{r}
lseq <- function(from,to, length.out) {
  exp(seq(log(from), log(to), length.out = length.out))
}
RetroDuration_clean %>%
  ggplot(aes(x = rEstimatedDuration, col = Session, fill = Session)) +
  geom_histogram(aes(y = after_stat(ncount)), col = NA, position = 'dodge', breaks = lseq(.1,10,10), alpha = .3) +
  stat_ecdf() +
  facet_wrap(~Country) +
  scale_x_log10() +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session)
```

Dashed = original data, continuous = outliers removed. Thin black vertical lines = hard limits (`Duration_min` and `Duration_max`).
We notice here that SC shows a strong outlier suppression on the right side. This is due to highly rounded responses with few subjects.

```{r}

ggplot(RetroDuration_clean,aes(x=ClockDuration,col=Session)) +
  stat_ecdf() +
  # facet_grid(Country~Session) +
  facet_wrap(~Session) +
  stat_ecdf(data = RetroDuration, linetype = 2) +
  geom_vline(xintercept = c(Duration_min,Duration_max), size = .1) +
  theme_minimal() +
  ylab('Empirical cumulated density') +
  scale_x_log10() +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session) +
  ggtitle('Distributions of ClockDuration before/after outlier rejection')

ggplot(RetroDuration_clean,aes(x=EstimatedDuration,col=Session)) +
  stat_ecdf() +
  # facet_grid(Country~Session) +
  facet_wrap(~Session) +
  stat_ecdf(data = RetroDuration, linetype = 2) +
  geom_vline(xintercept = c(Duration_min,Duration_max) * Ratio_rejection_ClockDuration_to_EstimatedDuration, size = .1) +
  theme_minimal() +
  ylab('Empirical cumulated density') +
  scale_x_log10() +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session) +
  ggtitle('Distributions of EstimatedDuration before/after outlier rejection')

ggplot(RetroDuration_clean,aes(x=rEstimationError,col=Session)) +
  stat_ecdf() +
  # facet_grid(Country~Session) +
  facet_wrap(~Session) +
  stat_ecdf(data = RetroDuration, linetype = 2) +
  theme_minimal() +
  ylab('Empirical cumulated density') +
  scale_x_log10() +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session) +
  ggtitle('Distributions of rEstimationError before/after outlier rejection')


# ggplot(RetroDuration, aes(y = rEstimationError, x = Session, col = Country)) +
#   geom_boxplot() +
#   coord_cartesian(ylim = c(-20, 20)) +
#   ggtitle('rEstimationError before outlier rejection')
# ggplot(RetroDuration_clean, aes(y = rEstimationError, x = Session, col = Country)) +
#   geom_boxplot() +
#   coord_cartesian(ylim = c(-20, 20)) +
#   ggtitle('rEstimationError after outlier rejection')

```
## Subjects Count after outlier rejection

```{r}

RetroDuration_clean %>% group_by(Country, Session) %>%
  summarize(n = n())


```

```{r}
skimr::skim(RetroDuration_clean)
```

# ratio rEstimatedDuration = EstimatedDuration / ClockDuration

## Focus on S1 vs. SC comparison

```{r}
load(file = file.path(dirBlursday, 'RetroDuration_clean.RData'))

tostat <- RetroDuration_clean %>% 
  group_by(Country, PID, Session) %>%
  select(Country,PID, Session, Local_Date,EstimatedDuration, rEstimatedDuration, EstimationError, Age, Sex, Handedness, ClockDuration) %>%
  filter(Session %in% c('S1','SC')) %>%
  summarize(Local_Date = unique(Local_Date),
            EstimationError = mean(EstimationError) / 60,
            ClockDuration = mean(ClockDuration) / 60,
            EstimatedDuration = mean(EstimatedDuration) / 60,
            rEstimatedDuration = mean(rEstimatedDuration),
            rEstimationError = mean(EstimationError/ClockDuration),
            Age = unique(Age)) %>%
  mutate(logrEstimatedDuration = log10(rEstimatedDuration)) %>%
  add_SubjectiveConfinementIndices() %>%
  add_StringencyIndex() %>%
  add_TimeOfDay()

N <- tostat %>%
  group_by(Session) %>%
  summarize(N = n())
```

```{r}
skimr::skim(ungroup(tostat))
```

#### Examining distributions

Two largely overlapping distributions, same central tendency, heavier tails for SC.

```{r}
ggplot(tostat,aes(y = ClockDuration, x = Session, col=Session)) +
  geom_beeswarm(priority = 'random',cex = .3, col = 'grey') +
  geom_violin(fill = NA, draw_quantiles = .5, na.rm = T) +
  geom_text(aes(label = paste0('N = ',N)), nudge_x = -.3, y = 2, data = N, show.legend = F) +
  theme_minimal() +
  scale_y_log10() +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  ylab('ClockDuration (min)')

ggplot(tostat,aes(x=ClockDuration,col = Session)) +
  stat_ecdf() +
  theme_minimal() + 
  scale_x_log10() +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  xlab('ClockDuration (min)') +
  ylab('Proportion')
# t.test(ClockDuration ~ Session, data = tostat, var.equal= TRUE)

```

Two largely overlapping distributions, same central tendency, highly granular responses.

```{r}
ggplot(tostat,aes(y=EstimatedDuration,x = Session, col=Session)) +
  geom_beeswarm(priority = 'random',cex = .3, col = 'grey') +
  geom_violin(fill = NA, draw_quantiles = .5, na.rm = T) +
  geom_text(aes(label = paste0('N = ',N)), nudge_x = -.3, y=2,data = N, show.legend = F) +
  theme_minimal() +
  scale_y_log10() +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  ylab('EstimatedDuration (min)')

ggplot(tostat,aes(x=EstimatedDuration,col = Session)) +
  stat_ecdf() +
  theme_minimal() + 
  scale_x_log10() +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  xlab('EstimatedDuration (min)') +
  ylab('Proportion')
# t.test(ClockDuration ~ Session, data = tostat, var.equal= TRUE)

```

Two largely overlapping distributions, same central tendency, heavier tails for S1.

```{r}
ggplot(tostat,aes(y=rEstimationError,x = Session, col=Session)) +
  geom_beeswarm(priority = 'random',cex = .3, col = 'grey') +
  geom_violin(fill = NA, draw_quantiles = .5, na.rm = T) +
  geom_text(aes(label = paste0('N = ',N)), nudge_x = -.3,y=3.5,data = N, show.legend = F) +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  theme_minimal()
# +
#   coord_cartesian(ylim = c(-1,4))

ggplot(tostat,aes(x=rEstimationError,col = Session)) +
  stat_ecdf() +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  theme_minimal()
# t.test(tostat[tostat$Session == 'S1',]$rEstimationError)
# t.test(tostat[tostat$Session == 'SC',]$rEstimationError)
# t.test(rEstimationError ~ Session, data = tostat, var.equal= TRUE)

```


```{r}
ggplot(tostat,aes(y=rEstimatedDuration,x = Session, col=Session)) +
  geom_beeswarm(priority = 'random',cex = .5, col = 'grey') +
  geom_violin(fill = NA, draw_quantiles = .5, na.rm = T) +
  geom_text(aes(label = paste0('N = ',N)), nudge_x = -.3, y=log10(3), data = N, show.legend = F) +
  theme_minimal() +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  scale_y_log10()


ggplot(tostat,aes(x=rEstimatedDuration,col = Session)) +
  stat_ecdf() +
  theme_minimal() +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  scale_x_log10()
# t.test(log10(tostat[tostat$Session == 'S1',]$rEstimatedDuration))
# t.test(log10(tostat[tostat$Session == 'SC',]$rEstimatedDuration))
# t.test(log10(rEstimatedDuration) ~ Session, data = tostat, var.equal= TRUE)
# 
# tostat %>%
#   group_by(Session)%>%
#   mutate(Age = scale(Age,center = T, scale = F),
#          Session = factor(Session)) %>%
#   filter(!is.na(Age)) %>%
# aov_ez(id = 'PID', dv = 'logrEstimatedDuration', data = ., between = 'Session', covariate = 'Age', factorize = F)

```

#### Model log(EstimatedDuration) = f(log(ClockDuration))

```{r}
m <- lm(log10(EstimatedDuration) ~ log10(ClockDuration) * Session, data = tostat) #  %>% mutate(Session = factor(Session,levels = c('SC', 'S1')))
plot(m)
```

Outliers are more transparent.

```{r}
emmeans(m,~ClockDuration+Session,at = list(ClockDuration = seq(min(tostat$ClockDuration,na.rm = F), max(tostat$ClockDuration,na.rm = F), length.out = 20))) %>%
  summary(type = 'response') %>%
  ggplot(aes(x = ClockDuration, y = response, ymin = lower.CL, ymax = upper.CL, col = Session, group = Session)) +
  geom_abline(slope = 1) +
  geom_point(aes(y= EstimatedDuration, ymin = NA, ymax = NA),alpha = .1, data = RetroDuration %>%
               filter(Session %in% c('S1','SC')) %>%
               group_by(Country, PID, Session) %>%
               mutate(EstimationError = mean(EstimationError) / 60,
                      ClockDuration = mean(ClockDuration) / 60,
                      EstimatedDuration = mean(EstimatedDuration) / 60)) +
  geom_point(aes(y= EstimatedDuration, ymin = NA, ymax = NA),alpha = .5,data = tostat) +
  geom_line(size = 1) +
  geom_ribbon(col = NA, fill = 'grey',alpha = .2) +
  scale_x_log10() +
  scale_y_log10() +
  ylab('Duration Estimates (min)') +
  xlab('Clock Duration (min)') +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  theme_minimal()
```
Not showing outliers
```{r}
emmeans(m,~ClockDuration+Session,at = list(ClockDuration = seq(min(tostat$ClockDuration,na.rm = F), max(tostat$ClockDuration,na.rm = F), length.out = 20))) %>%
  summary(type = 'response') %>%
  ggplot(aes(x = ClockDuration, y = response, ymin = lower.CL, ymax = upper.CL, col = Session, group = Session)) +
  geom_abline(slope = 1) +
  geom_point(aes(y= EstimatedDuration, ymin = NA, ymax = NA),alpha = .5,data = tostat) +
  geom_line(size = 1) +
  geom_ribbon(col = NA, fill = 'grey',alpha = .2) +
  scale_x_log10() +
  scale_y_log10() +
  ylab('Duration Estimate (min)') +
  xlab('Clock Duration (min)') +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC)

imagefile = '/home/maximilien.chaumon_local/ownCloud/Lab/00-Projects/TimeSocialDistancing/PaperFigures/Fig4a.png'
ggsave(
  basename(imagefile),
  plot = last_plot(),
  device = 'png',
  width = 200,
  height = 100,
  path = dirname(imagefile),
  units = 'mm',
  bg = "white"
)

googledrive::drive_auth()
googledrive::drive_upload(imagefile,
                          path = googledrive::as_dribble('https://drive.google.com/drive/folders/1OA-YRMBgo93zkndKHvUH0zR8LQAzBto8'),
                          overwrite = T)
```

```{r}
summary(m)

summary(emtrends(m,~Session, 'log10(ClockDuration)'))

anova(m)

summary(emmeans(m,~ClockDuration+Session,at = list(ClockDuration = c(10,30,60))),type = 'response') %>%
  mutate(ClockDuration = lubridate::as.duration(ClockDuration * 60),
         response = lubridate::as.duration(response * 60))


summary(emmeans(m,~ClockDuration+Session,at = list(ClockDuration = seq(15,20, by = .1))),type = 'response') %>%
  mutate(ClockDuration = lubridate::as.duration(ClockDuration * 60),
         response = lubridate::as.duration(response * 60),
         identity = response - ClockDuration) %>%
  group_by(Session) %>%
  filter(abs(identity) == min(abs(identity))) %>%
  select(-response)


tostat %>% group_by(Session) %>% summarize(mean_ClockDuration = mean(ClockDuration))


```


### Effect of age and Hour of day

```{r}
tostat %>%
  ggplot(aes(x=Age,y = after_stat(ncount), fill = Session)) +
  geom_histogram(position = 'dodge') +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  ylab('normalized count')
```

```{r}
m <- lm(log10(EstimatedDuration) ~ log10(ClockDuration) * Session + log10(ClockDuration) * Age + log10(ClockDuration) * poly(Hour_Of_Day,3), data = tostat)
summary(m)
plot(m)
anova(m)
```


```{r}
emmeans(m,~ClockDuration+Age,at = list(ClockDuration = seq(min(tostat$ClockDuration,na.rm = F), max(tostat$ClockDuration,na.rm = F), length.out = 80), Age = seq(20,80,10))) %>%
  summary(type = 'response') %>%
  ggplot(aes(x = ClockDuration, y = response, ymin = lower.CL, ymax = upper.CL, col = Age, group = Age)) +
  geom_point(aes(y=EstimatedDuration,ymin = NA, ymax = NA),alpha = .5,data = tostat) +
  geom_abline(slope = 1) +
  geom_ribbon(col = NA, fill = 'grey',alpha = .2) +
  geom_line(size = 1) +
  scale_x_log10() +
  scale_y_log10() +
  ylab('EstimatedDuration (s)') +
  xlab('Clock Duration (s)') +
  theme_minimal()
```

```{r}
emmeans(m,~ClockDuration + Hour_Of_Day,at = list(ClockDuration = seq(min(tostat$ClockDuration,na.rm = F), max(tostat$ClockDuration,na.rm = F), length.out = 80), Hour_Of_Day = seq(0,23))) %>%
  summary(type = 'response') %>%
  ggplot(aes(x = ClockDuration, y = response, ymin = lower.CL, ymax = upper.CL, col = Hour_Of_Day, group = Hour_Of_Day)) +
  geom_point(aes(y=EstimatedDuration,ymin = NA, ymax = NA),alpha = .5,data = tostat) +
  geom_abline(slope = 1) +
  geom_ribbon(col = NA, fill = 'grey',alpha = .2) +
  geom_line(size = 1) +
  scale_x_log10() +
  scale_y_log10() +
  ylab('EstimatedDuration (s)') +
  xlab('Clock Duration (s)') +
  theme_minimal()

```

## Focus on countries that have S1 and SC (FR, IT, JP)

```{r}
load(file = file.path(dirBlursday, 'RetroDuration_clean.RData'))

tostat <- RetroDuration_clean %>% 
  group_by(Country, PID, Session) %>%
  select(Country,PID, Session, Local_Date,EstimatedDuration, rEstimatedDuration, EstimationError, Age, Sex, Handedness, ClockDuration) %>%
  filter(Session %in% c('S1','SC'), 
         Country %in% c('FR','IT','JP')) %>%
  summarize(Local_Date = unique(Local_Date),
            EstimationError = mean(EstimationError) / 60,
            ClockDuration = mean(ClockDuration) / 60,
            EstimatedDuration = mean(EstimatedDuration) / 60,
            rEstimatedDuration = mean(rEstimatedDuration),
            rEstimationError = mean(EstimationError/ClockDuration),
            Age = unique(Age)) %>%
  mutate(logrEstimatedDuration = log10(rEstimatedDuration)) %>%
  add_SubjectiveConfinementIndices() %>%
  add_StringencyIndex() %>%
  add_TimeOfDay()

N <- tostat %>%
  group_by(Session) %>%
  summarize(N = n())
```

```{r}
skimr::skim(ungroup(tostat))
```

#### Examining distributions

Two largely overlapping distributions, same central tendency, heavier tails for SC.

```{r}
ggplot(tostat,aes(y = ClockDuration, x = Session, col=Session)) +
  geom_beeswarm(priority = 'random',cex = .3, col = 'grey') +
  geom_violin(fill = NA, draw_quantiles = .5, na.rm = T) +
  geom_text(aes(label = paste0('N = ',N)), nudge_x = -.3, y = 2, data = N, show.legend = F) +
  theme_minimal() +
  scale_y_log10() +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  ylab('ClockDuration (min)')

ggplot(tostat,aes(x=ClockDuration,col = Session)) +
  stat_ecdf() +
  theme_minimal() + 
  scale_x_log10() +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  xlab('ClockDuration (min)') +
  ylab('Proportion')
# t.test(ClockDuration ~ Session, data = tostat, var.equal= TRUE)

```


Two largely overlapping distributions, same central tendency, highly granular responses.

```{r}
ggplot(tostat,aes(y=EstimatedDuration,x = Session, col=Session)) +
  geom_beeswarm(priority = 'random',cex = .3, col = 'grey') +
  geom_violin(fill = NA, draw_quantiles = .5, na.rm = T) +
  geom_text(aes(label = paste0('N = ',N)), nudge_x = -.3, y=2,data = N, show.legend = F) +
  theme_minimal() +
  scale_y_log10() +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  ylab('EstimatedDuration (min)')

ggplot(tostat,aes(x=EstimatedDuration,col = Session)) +
  stat_ecdf() +
  theme_minimal() + 
  scale_x_log10() +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  xlab('EstimatedDuration (min)') +
  ylab('Proportion')
# t.test(ClockDuration ~ Session, data = tostat, var.equal= TRUE)

```


Two largely overlapping distributions, same central tendency, heavier tails for S1.

```{r}
ggplot(tostat,aes(y=rEstimationError,x = Session, col=Session)) +
  geom_beeswarm(priority = 'random',cex = .3, col = 'grey') +
  geom_violin(fill = NA, draw_quantiles = .5, na.rm = T) +
  geom_text(aes(label = paste0('N = ',N)), nudge_x = -.3,y=3.5,data = N, show.legend = F) +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  theme_minimal()
# +
#   coord_cartesian(ylim = c(-1,4))

ggplot(tostat,aes(x=rEstimationError,col = Session)) +
  stat_ecdf() +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  theme_minimal()
# t.test(tostat[tostat$Session == 'S1',]$rEstimationError)
# t.test(tostat[tostat$Session == 'SC',]$rEstimationError)
# t.test(rEstimationError ~ Session, data = tostat, var.equal= TRUE)

```


```{r}
ggplot(tostat,aes(y=rEstimatedDuration,x = Session, col=Session)) +
  geom_beeswarm(priority = 'random',cex = .5, col = 'grey') +
  geom_violin(fill = NA, draw_quantiles = .5, na.rm = T) +
  geom_text(aes(label = paste0('N = ',N)), nudge_x = -.3, y=log10(3), data = N, show.legend = F) +
  theme_minimal() +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  scale_y_log10()


ggplot(tostat,aes(x=rEstimatedDuration,col = Session)) +
  stat_ecdf() +
  theme_minimal() +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  scale_x_log10()
# t.test(log10(tostat[tostat$Session == 'S1',]$rEstimatedDuration))
# t.test(log10(tostat[tostat$Session == 'SC',]$rEstimatedDuration))
# t.test(log10(rEstimatedDuration) ~ Session, data = tostat, var.equal= TRUE)
# 
# tostat %>%
#   group_by(Session)%>%
#   mutate(Age = scale(Age,center = T, scale = F),
#          Session = factor(Session)) %>%
#   filter(!is.na(Age)) %>%
# aov_ez(id = 'PID', dv = 'logrEstimatedDuration', data = ., between = 'Session', covariate = 'Age', factorize = F)

```

#### Model log(EstimatedDuration) = f(log(ClockDuration))

```{r}
m <- lm(log10(EstimatedDuration) ~ log10(ClockDuration) * Session, data = tostat) #  %>% mutate(Session = factor(Session,levels = c('SC', 'S1')))
plot(m)
```

Outliers are more transparent.

```{r}
emmeans(m,~ClockDuration+Session,at = list(ClockDuration = seq(min(tostat$ClockDuration,na.rm = F), max(tostat$ClockDuration,na.rm = F), length.out = 20))) %>%
  summary(type = 'response') %>%
  ggplot(aes(x = ClockDuration, y = response, ymin = lower.CL, ymax = upper.CL, col = Session, group = Session)) +
  geom_abline(slope = 1) +
  geom_point(aes(y= EstimatedDuration, ymin = NA, ymax = NA),alpha = .1, data = RetroDuration %>%
               filter(Session %in% c('S1','SC')) %>%
               group_by(Country, PID, Session) %>%
               mutate(EstimationError = mean(EstimationError) / 60,
                      ClockDuration = mean(ClockDuration) / 60,
                      EstimatedDuration = mean(EstimatedDuration) / 60)) +
  geom_point(aes(y= EstimatedDuration, ymin = NA, ymax = NA),alpha = .5,data = tostat) +
  geom_line(size = 1) +
  geom_ribbon(col = NA, fill = 'grey',alpha = .2) +
  scale_x_log10() +
  scale_y_log10() +
  ylab('EstimatedDuration (min)') +
  xlab('Clock Duration (min)') +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  theme_minimal()
```
Not showing outliers
```{r}
emmeans(m,~ClockDuration+Session,at = list(ClockDuration = seq(min(tostat$ClockDuration,na.rm = F), max(tostat$ClockDuration,na.rm = F), length.out = 20))) %>%
  summary(type = 'response') %>%
  ggplot(aes(x = ClockDuration, y = response, ymin = lower.CL, ymax = upper.CL, col = Session, group = Session)) +
  geom_abline(slope = 1) +
  geom_point(aes(y= EstimatedDuration, ymin = NA, ymax = NA),alpha = .5,data = tostat) +
  geom_line(size = 1) +
  geom_ribbon(col = NA, fill = 'grey',alpha = .2) +
  scale_x_log10() +
  scale_y_log10() +
  ylab('EstimatedDuration (min)') +
  xlab('Clock Duration (min)') +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  theme_minimal()
```

```{r}
summary(m)
anova(m)

summary(emmeans(m,~ClockDuration+Session,at = list(ClockDuration = c(10,30,60))),type = 'response') %>%
  mutate(ClockDuration = lubridate::as.duration(ClockDuration * 60),
         response = lubridate::as.duration(response * 60))


summary(emmeans(m,~ClockDuration+Session,at = list(ClockDuration = seq(15,20, by = .1))),type = 'response') %>%
  mutate(ClockDuration = lubridate::as.duration(ClockDuration * 60),
         response = lubridate::as.duration(response * 60),
         identity = response - ClockDuration) %>%
  group_by(Session) %>%
  filter(abs(identity) == min(abs(identity))) %>%
  select(-response)


tostat %>% group_by(Session) %>% summarize(mean_ClockDuration = mean(ClockDuration))

```


### Effect of age and hour of the day

```{r}
tostat %>%
  ggplot(aes(x=Age,y = after_stat(ncount), fill = Session)) +
  geom_histogram(position = 'dodge') +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC) +
  ylab('normalized count')
```

```{r}
m <- lm(log10(EstimatedDuration) ~ log10(ClockDuration) * Session + log10(ClockDuration) * Age + log10(ClockDuration) * poly(Hour_Of_Day,3), data = tostat)
summary(m)
plot(m)
anova(m)
```


```{r}
emmeans(m,~ClockDuration+Age,at = list(ClockDuration = seq(min(tostat$ClockDuration,na.rm = F), max(tostat$ClockDuration,na.rm = F), length.out = 80), Age = seq(20,80,10))) %>%
  summary(type = 'response') %>%
  ggplot(aes(x = ClockDuration, y = response, ymin = lower.CL, ymax = upper.CL, col = Age, group = Age)) +
  geom_point(aes(y=EstimatedDuration,ymin = NA, ymax = NA),alpha = .5,data = tostat) +
  geom_abline(slope = 1) +
  geom_ribbon(col = NA, fill = 'grey',alpha = .2) +
  geom_line(size = 1) +
  scale_x_log10() +
  scale_y_log10() +
  ylab('EstimatedDuration (s)') +
  xlab('Clock Duration (s)') +
  theme_minimal()
```

```{r}
emmeans(m,~ClockDuration + Hour_Of_Day,at = list(ClockDuration = seq(min(tostat$ClockDuration,na.rm = F), max(tostat$ClockDuration,na.rm = F), length.out = 80), Hour_Of_Day = seq(0,23))) %>%
  summary(type = 'response') %>%
  ggplot(aes(x = ClockDuration, y = response, ymin = lower.CL, ymax = upper.CL, col = Hour_Of_Day, group = Hour_Of_Day)) +
  geom_point(aes(y=EstimatedDuration,ymin = NA, ymax = NA),alpha = .5,data = tostat) +
  geom_abline(slope = 1) +
  geom_ribbon(col = NA, fill = 'grey',alpha = .2) +
  geom_line(size = 1) +
  scale_x_log10() +
  scale_y_log10() +
  ylab('EstimatedDuration (s)') +
  xlab('Clock Duration (s)') +
  theme_minimal()

```


## All data and sessions

We first insert all covariates in the data, looking at all sessions, now.
```{r}
load(file = file.path(dirBlursday, 'RetroDuration_clean.RData'))
tostat <- RetroDuration_clean %>% 
  group_by(Country, PID, Session) %>%
  select(Country,PID, Session, Local_Date, EstimatedDuration, rEstimatedDuration, EstimationError, Age, Sex, Handedness, ClockDuration) %>%
  filter(!is.na(rEstimatedDuration), rEstimatedDuration != 0) %>%
  summarize(n = n(),
            Local_Date = unique(Local_Date),
            EstimatedDuration = mean(EstimatedDuration),
            rEstimatedDuration = mean(rEstimatedDuration),
            rEstimationError = mean(EstimationError/ClockDuration),
            EstimationError = mean(EstimationError),
            ClockDuration = mean(ClockDuration),
            Age = unique(Age)) %>%
  mutate(logrEstimatedDuration = log10(rEstimatedDuration)) %>%
  add_SubjectiveConfinementDuration() %>%
  add_SubjectiveConfinementIndices() %>%
  add_Mobility() %>%
  add_StringencyIndex() %>%
  add_TimeOfDay()

(N <- tostat %>%
  group_by(Session) %>%
  summarize(N = n()))
```

```{r}
skimr::skim(ungroup(tostat))
```

```{r}
tostat %>%
  group_by(Country,PID,Session) %>%
  slice(1) %>%
  ggplot(aes(x=Stringency_Index,fill = Session, y = after_stat(ncount)),data = .) +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session) +
  geom_histogram(breaks = seq(0,100,by=5), position = 'dodge')
  
```
```{r}
tostat %>%
  group_by(Country,PID,Session) %>%
  slice(1) %>%
  ggplot(aes(x=Mobility_Transit,fill = Session, y = after_stat(ncount)),data = .) +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session) +
  geom_histogram(bins = 20, position = 'dodge')
  
```

```{r}
tostat %>%
  group_by(Country,PID,Session) %>%
  slice(1) %>%
  pivot_longer(cols = starts_with('Mobility_'), names_to = 'Mobility', values_to = 'Percent_from_baseline', names_prefix = 'Mobility_') %>%
  ggplot(aes(x=Percent_from_baseline,fill = Session, y = after_stat(ncount)),data = .) +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session) +
  geom_histogram(bins = 30, position = 'dodge') +
  facet_wrap(~Mobility, scales = 'free_x')
  
```

#### Modeling

Subjects were repeatedly tested in S1-S4, and a different pool of subjects were tested in SC.
We thus try to see if the error related to subjects in the intercept of EstimatedDuration is worth modeling as a random effect.
The standard deviation of the estimated random effects is much smaller than that of the residuals, suggesting that random effects can be ignored in this case.

```{r}
# # m <- aov_4(data = tostat, log10(rEstimatedDuration) ~ Stringency_Index + Subjective_Confinement + Time_Of_Day + (1 | PID))
# # 
# # m <- aov_ez(id = 'PID', dv = 'logrEstimatedDuration', within = c('Stringency_Index', 'Subjective_Confinement', 'Time_Of_Day'), data = tostat)
# 
# # %>% filter(!(Session == 'SC' & Country == 'IT') & !(Session == 'SC' & Country == 'JP'))

m <- lmerTest::lmer(log10(rEstimatedDuration) ~ Stringency_Index + Subjective_Confinement + Age + poly(Hour_Of_Day,3) +  (1 | PID), data = tostat )
summary(m)
anova(m)
effectsize::eta_squared(m)
```

Indeed, running a simple lm on the data with the same fixed effects retrieves the same effects.

```{r}
m <- lm(log10(rEstimatedDuration) ~ Stringency_Index + Subjective_Confinement + Age + poly(Hour_Of_Day,3), data = tostat)
summary(m)
anova(m)
effectsize::eta_squared(m)

plot(m)


```

Same reasoning with Mobility_Transit:

```{r}
m <- lmerTest::lmer(log10(rEstimatedDuration) ~ Stringency_Index + Mobility_Transit + Subjective_Confinement + Age  +  poly(Hour_Of_Day,3) + (1 | PID), data = tostat )
summary(m)
anova(m)
effectsize::eta_squared(m)
```

Indeed, running a simple lm on the data with the same fixed effects retrieves the same effects.

```{r}
m <- lm(log10(rEstimatedDuration) ~ Stringency_Index + Mobility_Transit + Subjective_Confinement + Age + poly(Hour_Of_Day,3), data = tostat)
summary(m)
anova(m)
effectsize::eta_squared(m)

plot(m)


```
#### Illustrating

##### Stringency Index

```{r}

em <- summary(emmeans(m, ~ Stringency_Index, at = list(Stringency_Index = seq(20,100,by = 20))), type = 'response')

ggplot(aes(x = Stringency_Index,y = rEstimatedDuration, col = Session), data = tostat) +
  geom_col(aes(y=response), col = 'black', data = em) +
  geom_pointrange(aes(y=response, ymin = lower.CL, ymax = upper.CL), col = 'black', data = em) +
  scale_y_log10(limits = c(.3,3)) +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session)

ggplot(aes(x = Stringency_Index,y = rEstimatedDuration, col = Session), data = tostat) +
  geom_jitter(alpha = .3) +
  geom_line(aes(y=response), col = 'black', data = em) +
  geom_ribbon(aes(y=response, ymin = lower.CL, ymax = upper.CL), col = NA, alpha = .2, data = em) +
  scale_y_log10( limits = c(.3,3)) +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session) +
  ylab('Relative Duration Estimate') +
  xlab('Stringency Index')
em

imagefile = '/home/maximilien.chaumon_local/ownCloud/Lab/00-Projects/TimeSocialDistancing/PaperFigures/Fig4b.png'
ggsave(
  basename(imagefile),
  plot = last_plot(),
  device = 'png',
  width = 200,
  height = 100,
  path = dirname(imagefile),
  units = 'mm',
  bg = "white"
)

googledrive::drive_auth()
googledrive::drive_upload(imagefile,
                          path = googledrive::as_dribble('https://drive.google.com/drive/folders/1OA-YRMBgo93zkndKHvUH0zR8LQAzBto8'),
                          overwrite = T)
```
##### Mobility Transit

```{r}

em <- summary(emmeans(m, ~ Mobility_Transit, at = list(Mobility_Transit = seq(-100,10,by = 10))), type = 'response')

ggplot(aes(x = Mobility_Transit,y = rEstimatedDuration, col = Session), data = tostat) +
  geom_col(aes(y=response), col = 'black', data = em) +
  geom_pointrange(aes(y=response, ymin = lower.CL, ymax = upper.CL), col = 'black', data = em) +
  scale_y_log10(limits = c(.3,3)) +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session)

ggplot(aes(x = Mobility_Transit,y = rEstimatedDuration, col = Session), data = tostat) +
  geom_jitter(alpha = .3) +
  geom_line(aes(y=response), col = 'black', data = em) +
  geom_ribbon(aes(y=response, ymin = lower.CL, ymax = upper.CL), col = NA, alpha = .2, data = em) +
  scale_y_log10( limits = c(.3,3)) +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session) +
  ylab('Relative Duration Estimate') +
  xlab('Mobility Index')
em

imagefile = '/home/maximilien.chaumon_local/ownCloud/Lab/00-Projects/TimeSocialDistancing/PaperFigures/Fig4c.png'
ggsave(
  basename(imagefile),
  plot = last_plot(),
  device = 'png',
  width = 200,
  height = 100,
  path = dirname(imagefile),
  units = 'mm',
  bg = "white"
)

googledrive::drive_auth()
googledrive::drive_upload(imagefile,
                          path = googledrive::as_dribble('https://drive.google.com/drive/folders/1OA-YRMBgo93zkndKHvUH0zR8LQAzBto8'),
                          overwrite = T)
```
Other mobility measures have little effect on rEstimatedDuration
```{r}
m <- lm(log10(rEstimatedDuration) ~ Stringency_Index + Mobility_Transit + Mobility_Retail + Mobility_Parks + Mobility_WorkPlaces + Mobility_Residential + Subjective_Confinement + Age + poly(Hour_Of_Day,3), data = tostat)
summary(m)
anova(m)
effectsize::eta_squared(m)

plot(m)


```


```{r}
emm <- emmeans(m, ~ Stringency_Index, at = list(Stringency_Index = seq(20,100,by = 20)))
em <- predict(emm, type = 'response', interval = 'prediction')


ggplot(aes(x = Stringency_Index,y = rEstimatedDuration, col = Session), data = tostat) +
  geom_jitter(alpha = .3) +
  geom_line(aes(y=prediction), col = 'black', data = em) +
  geom_ribbon(aes(y=prediction, ymin = lower.PL, ymax = upper.PL), col = NA, alpha = .2, data = em) +
  scale_y_log10( limits = c(.3,3)) +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session)

```

<!-- ```{r} -->
<!-- em <- summary(emmeans(m, ~ Stringency_Index, at = list(Stringency_Index = seq(min(tostat$Stringency_Index, na.rm = T),max(tostat$Stringency_Index, na.rm = T), by=5)))) -->

<!-- ggplot(aes(x = Stringency_Index,y = log10(rEstimatedDuration), col = Session), data = tostat) + -->
<!--   geom_point(alpha = .3) + -->
<!--   geom_ribbon(aes(y=emmean, ymin = lower.CL, ymax = upper.CL), col = NA, alpha = .1, data = em) + -->
<!--   geom_line(aes(y=emmean), col = 'black', data = em) -->

<!-- em <- summary(emmeans(m, ~ Stringency_Index, at = list(Stringency_Index = seq(0,100,by = 20)))) -->

<!-- ggplot(aes(x = Stringency_Index,y = log10(rEstimatedDuration), col = Session), data = tostat) + -->
<!--   geom_point(alpha = .3) + -->
<!--   geom_col(aes(y=emmean), col = 'black', data = em) + -->
<!--   geom_pointrange(aes(y=emmean, ymin = lower.CL, ymax = upper.CL), col = 'black', data = em) + -->
<!--   scale_y_continuous(limits = c(-.2,.2)) -->

<!-- em <- summary(emmeans(m, ~ Stringency_Index, at = list(Stringency_Index = seq(20,100,by = 20))), type = 'response') -->


<!-- ggplot(aes(x = Stringency_Index,y = rEstimatedDuration, col = Session), data = tostat) + -->
<!--   geom_point(alpha = .3) + -->
<!--   geom_col(aes(y=response), col = 'black', data = em) + -->
<!--   geom_pointrange(aes(y=response, ymin = lower.CL, ymax = upper.CL), col = 'black', data = em) + -->
<!--   scale_y_log10(limits = c(.3,3)) -->

<!-- ggplot(aes(x = Stringency_Index,y = rEstimatedDuration, col = Session), data = tostat) + -->
<!--   geom_point(alpha = .3) + -->
<!--   geom_col(aes(y=response), col = 'black', data = em) + -->
<!--   geom_pointrange(aes(y=response, ymin = lower.CL, ymax = upper.CL), col = 'black', data = em) + -->
<!--   scale_y_log10() -->

<!-- ggplot(aes(x = Stringency_Index,y = rEstimatedDuration, col = Session), data = tostat) + -->
<!--   # geom_point(alpha = .3) +  -->
<!--   geom_col(aes(y=response), col = 'black', data = em) + -->
<!--   geom_pointrange(aes(y=response, ymin = lower.CL, ymax = upper.CL), col = 'black', data = em) + -->
<!--   scale_y_continuous(trans = t_shift, limits = c(.6,1.4)) -->
<!-- ``` -->

##### Time Of Day

```{r}
t_shift <- scales::trans_new("shift",
                             transform = function(x) {x-1},
                             inverse = function(x) {x+1})

em <- summary(emmeans(m, ~ Hour_Of_Day, at = list(Hour_Of_Day = seq(6,24, by=1))), type = 'response')


ggplot(aes(x = Hour_Of_Day,y = rEstimatedDuration, col = Session), data = tostat) +
  geom_col(aes(y=response), col = 'black', data = em) +
  geom_pointrange(aes(y=response, ymin = lower.CL, ymax = upper.CL), col = 'black', data = em) +
  scale_y_continuous(trans = t_shift, limits = c(.3,3)) +
  xlim(c(7,23)) +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session)

ggplot(aes(x = Hour_Of_Day,y = rEstimatedDuration, col = Session), data = tostat) +
  geom_point(alpha = .3) +
  geom_line(aes(y=response), col = 'black', data = em) +
  geom_ribbon(aes(y=response, ymin = lower.CL, ymax = upper.CL), col = NA, alpha = .2, data = em) +
  scale_y_continuous(trans = t_shift, limits = c(.3,3)) +
  xlim(c(7,23)) +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session)
```
```{r}
em <- predict(emmeans(m, ~ Hour_Of_Day, at = list(Hour_Of_Day = seq(6,24, by=1))), type = 'response', interval = 'prediction')


ggplot(aes(x = Hour_Of_Day,y = rEstimatedDuration, col = Session), data = tostat) +
  geom_point(alpha = .3) +
  geom_line(aes(y=prediction), col = 'black', data = em) +
  geom_ribbon(aes(y=prediction, ymin = lower.PL, ymax = upper.PL), col = NA, alpha = .2, data = em) +
  scale_y_continuous(trans = t_shift, limits = c(.3,3)) +
  xlim(c(7,23)) +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session)
```

