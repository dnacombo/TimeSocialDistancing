---
title: "Retrospective duration: Passage of Time"
params:
  ExperimentID: null
output:
  html_notebook:
    code_folding: hide
    toc: yes
  html_document:
    df_print: paged
    code_folding: hide
    toc: yes
editor_options: 
  chunk_output_type: inline
---

<!-- # This is the Blursday database paper source code. -->
<!-- # This code was used to prepare the following article: -->
<!-- # XXX Ref. to add XXX -->
<!-- # -->
<!-- # The live application of the server can be accessed at  -->
<!-- # https://dnacombo.shinyapps.io/Blursday/ -->
<!-- # This code is publicly available at -->
<!-- # https://github.com/dnacombo/TSDshiny -->

<!-- #     Copyright (C) 2021  Maximilien Chaumon -->
<!-- # -->
<!-- #     This program is free software: you can redistribute it and/or modify -->
<!-- #     it under the terms of the GNU General Public License as published by -->
<!-- #     the Free Software Foundation, either version 3 of the License, or -->
<!-- #     (at your option) any later version. -->
<!-- # -->
<!-- #     This program is distributed in the hope that it will be useful, -->
<!-- #     but WITHOUT ANY WARRANTY; without even the implied warranty of -->
<!-- #     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the -->
<!-- #     GNU General Public License for more details. -->
<!-- # -->
<!-- #     You should have received a copy of the GNU General Public License -->
<!-- #     along with this program.  If not, see <http://www.gnu.org/licenses/>. -->

```{r, message=F}
library(tidyverse)
library(ggbeeswarm)
library(flextable)
library(MaxPac)
# library(afex)
library(emmeans)
library(effectsize)
theme_set(theme_minimal())

source('helpers.R')


```

# Reading data

We read data from the `RetroDuration` questionnaire. Translate responses using QTranslate() (google sheet). Read response to the `initial_RetrospectiveDuration` question. Extract estimated duration since last login as `##:##:##` --\> Hours:Minutes:Seconds. Compute `ClockDuration` as the difference between current time and last login.

```{r, message=F}
# load(file.path(dirBlursday,'Demographics.RData'))
load(file.path(dirBlursday,'Daily_Login_Times.RData'))

# Extracting data:

RetroDuration_PoT <- gimmeRdata(dirBlursday, UniqueName = 'RetroDuration') %>%
  filter(!Country %in% c('UK','CO', 'US')) %>%
  QTranslate() %>%
  filter(Question_Key %in% c('Passage_of_Time')) %>%
  mutate(Date = lubridate::date(Local_Date)) %>%
  pivot_wider(id_cols = c('PID', 'Session','Run', 'Country', 'Local_Date'), names_from = Question_Key, values_from = Response) %>%
  # take only the first response if there are several ones
  group_by(PID,Session,Run,Country) %>%
  slice(1) %>%
  add_Demographics() %>%
  # Using 3 AM to change day
  mutate(Date = lubridate::as_date(Local_Date - lubridate::duration(hours = 3)),
         Passage_of_Time = as.numeric(Passage_of_Time)) %>%
  left_join(select(daily_login_times, PID, Session, Local_Date, Date), by = c('PID','Date'), suffix = c('','_First_Login')) %>%
  mutate(Date = lubridate::as_date(Local_Date)) %>%
  mutate(ClockDuration = Local_Date - Local_Date_First_Login) %>%
  select(Country, PID, Session, Run, Local_Date, ClockDuration, Passage_of_Time,
         Handedness, Sex, Age, Date) %>%
  mutate(ClockDuration = lubridate::as.duration(ClockDuration)) %>%
  ungroup() %>%
  drop_na(Passage_of_Time, Age)

save(RetroDuration_PoT, file = file.path(dirBlursday,'RetroDuration_PoT.RData'))

load(file = file.path(dirBlursday,'RetroDuration_PoT.RData'))
```


# Outliers detection and clean up

```{r}
RetroDuration_PoT %>%
  mutate(across(c(ClockDuration, Passage_of_Time), as.numeric)) %>%
  pivot_longer(cols = c(ClockDuration,Passage_of_Time)) %>%
ggplot(aes(x = value, fill = Country)) + 
  geom_histogram(bins = 50) +
  facet_wrap(~name ,scales = 'free') +
  ggtitle('Measure distributions')
```

Distribution of `ClockDuration` is highly skewed to the left. First capping ClockDuration to decent durations, then removing 5% most extreme values.

Rationale:

-   `ClockDuration` cannot be below 60 s: no questionnaire/task can be completed under this duration, and we want at least one.
-   5% Largest/smallest `ClockDuration` is systematically discarded. This is done for each Session and Country separately.

We count these

```{r}
# capped_outliers:
Duration_max <- 18000
Duration_min <- 60
# trim_outliers:
probs <- c(.025, .975)

OutlierStats <- RetroDuration_PoT %>%
  group_by(Country,Session) %>%
  filter(!is.na(ClockDuration), ClockDuration != 0) %>%
  mutate(capped_outliers = ClockDuration > Duration_max | ClockDuration < Duration_min,
         ncapped_outliers = sum(capped_outliers, na.rm = T),
         prop_capped_outliers = ncapped_outliers/n()) %>%
  filter(!capped_outliers) %>%
  mutate(trim_outliers = find.outliers(ClockDuration,meth = 'trim', probs = probs),
         ntrim_outliers = sum(trim_outliers, na.rm = T)) %>%
  summarize(prop_trim_outliers = unique(ntrim_outliers)/n(),
            prop_capped_outliers = unique(prop_capped_outliers),
            ntrim_outliers = unique(ntrim_outliers),
            ncapped_outliers = unique(ncapped_outliers))
```


```{r}
OutlierStats %>% group_by() %>%
  summarize(across(starts_with('n'),list(sum = sum,
                                         min = min, 
                                         max = max,
                                         mean = mean,
                                         sd = sd))) %>%
  pivot_longer(starts_with('n')) %>%
  flextable() %>%
  colformat_double(big.mark = " ", digits = 3) 



OutlierStats %>%
  select(-starts_with('prop')) %>%
  pivot_wider(names_from = c(Session), values_from = c(ntrim_outliers, ncapped_outliers)) %>%
  flextable() %>%
  colformat_double(big.mark = " ", digits = 3) %>%
  add_header_lines('Number of outliers per Country x Session')
```


```{r}
OutlierStats %>% group_by() %>%
  summarize(across(starts_with('prop'),list(min = min, 
                                            max = max,
                                            mean = mean,
                                            sd = sd))) %>%
  pivot_longer(starts_with('prop')) %>%
  flextable() %>%
  colformat_double(big.mark = " ", digits = 3) 

OutlierStats %>%
  select(-starts_with('n')) %>%
  pivot_wider(names_from = c(Session), values_from = c(prop_trim_outliers,prop_capped_outliers)) %>%
  flextable() %>%
  colformat_double(big.mark = " ", digits = 3) %>%
  add_header_lines('Proportion of outliers per Country x Session')
```


```{r}
RetroDuration_PoT_clean <- RetroDuration_PoT %>%
  filter(!is.na(ClockDuration), ClockDuration != 0)
nrowsbefore_outliers <- nrow(RetroDuration_PoT_clean)
RetroDuration_PoT_clean <- RetroDuration_PoT_clean %>%
  group_by(Country,Session) %>%
  mutate(outliers = ClockDuration > Duration_max | ClockDuration < Duration_min) %>%
  filter(!outliers) %>%
  mutate(outliers = find.outliers(ClockDuration,meth = 'trim', probs = probs)) %>%
  filter(!outliers) %>%
  ungroup() %>% select(-outliers)
nrowsafter_outliers <- nrow(RetroDuration_PoT_clean)

cat('Global proportion of outliers', prop_outliers_global <- 1 - nrowsafter_outliers / nrowsbefore_outliers)

save(RetroDuration_PoT_clean, file = file.path(dirBlursday,'RetroDuration_PoT_clean.RData'))

RetroDuration_PoT_clean %>%
  group_by(Country,Session) %>%
  mutate(across(c(ClockDuration), as.numeric)) %>%
  pivot_longer(cols = c(ClockDuration, Passage_of_Time)) %>%
ggplot(aes(x = value, fill = Country)) + 
  geom_histogram(bins = 50) +
  facet_wrap(~name ,scales = 'free')
```

# Passage of Time
## Data distribution

```{r}
load(file = file.path(dirBlursday,'RetroDuration_PoT_clean.RData'))

RetroDuration_PoT_clean %>%
  group_by(Country,Session) %>%
ggplot(aes(x = Passage_of_Time, fill = Session)) + 
  geom_histogram(bins = 50)  +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session) +
  xlab('Passage of Time') +
  ylab('Count')

imagefile = '/home/maximilien.chaumon_local/ownCloud/Lab/00-Projects/TimeSocialDistancing/PaperFigures/SuppFig_distr_PoT.png'
ggsave(
  basename(imagefile),
  plot = last_plot(),
  device = 'png',
  width = 200,
  height = 100,
  path = dirname(imagefile),
  units = 'mm',
  bg = "white"
)
```


```{r}
googledrive::drive_auth()
googledrive::drive_upload(imagefile,
                          path = googledrive::as_dribble('https://drive.google.com/drive/folders/1OA-YRMBgo93zkndKHvUH0zR8LQAzBto8'),
                          overwrite = T)

```
```{r}
RetroDuration_PoT %>%
  group_by(Session,PID) %>%
  summarize(n = n()) %>%
  ggplot(aes(n,fill = Session)) +
  geom_histogram()
```


```{r}

ggplot(RetroDuration_PoT,aes(x=Passage_of_Time,col=Session)) +
  stat_ecdf() +
  # facet_grid(Country~Session) +
  theme_minimal() +
  ylab('Empirical cumulated density') +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session) +
  ggtitle('Distributions of Passage_of_Time')

```
## Subjects Count

```{r}

RetroDuration_PoT %>% group_by(Country, Session) %>%
  summarize(n = n())


```

```{r}
skimr::skim(RetroDuration_PoT_clean)
```




```{r}
ggplot(RetroDuration_PoT_clean,aes(x=Passage_of_Time,y=after_stat(ncount),fill=Session)) +
  geom_histogram(bins = 20, position='dodge') +
  ylab('Normalized counts') +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session)

```


# Modeling

```{r}
load(file = file.path(dirBlursday,'RetroDuration_PoT_clean.RData'))

tostat <- RetroDuration_PoT_clean %>% 
  group_by(Country, PID, Session) %>%
  select(Country,PID, Session, Local_Date, Age, Sex, Handedness, ClockDuration, Passage_of_Time) %>%
  filter(Session %in% c('S1','SC')) %>%
  summarize(Local_Date = unique(Local_Date),
            Age = unique(Age),
            Passage_of_Time = unique(Passage_of_Time),
            rPoT = Passage_of_Time / 50) %>%
  add_SubjectiveConfinementIndices() %>%
  add_Mobility() %>%
  add_StringencyIndex() %>%
  add_TimeOfDay() %>%
  mutate(Hour_Of_Day = recode(Hour_Of_Day,`0` = as.integer(24))) %>%
  drop_na(Stringency_Index, Subjective_Confinement)

N <- tostat %>%
  group_by(Session) %>%
  summarize(N = n())

skimr::skim(ungroup(tostat))
```

```{r}

ggplot(tostat,aes(x=rPoT,y=after_stat(ncount),fill=Session)) +
  geom_histogram(bins = 20, position='dodge') +
  ylab('Normalized counts') +
  scale_fill_manual(values = Palette_SessionS1SC) +
  scale_color_manual(values = Palette_SessionS1SC)

```

```{r}
ggplot(tostat,aes(y = rPoT, x = Session, col=Session)) +
  geom_beeswarm(priority = 'random',cex = .3, col = 'grey') +
  geom_violin(fill = NA, draw_quantiles = .5, na.rm = T) +
  geom_text(aes(label = paste0('N = ',N)), nudge_x = -.3, y = 1.5, data = N, show.legend = F) +
  theme_minimal() +
  ylab('Passage of Time')

ggplot(tostat,aes(x=rPoT,col = Session)) +
  stat_ecdf() +
  theme_minimal() + 
  xlab('Passage of Time') +
  ylab('Proportion') +
  scale_fill_manual(values = Palette_Session) +
  scale_color_manual(values = Palette_Session)

```

## Using lm

```{r}
mylm <- lm(Passage_of_Time ~ Stringency_Index + Mobility_Transit + Subjective_Confinement + Age  +  poly(Hour_Of_Day,3), data = tostat)
summary(mylm)

car::Anova(mylm, type = 2)

(em <- emmeans(mylm, ~ Subjective_Confinement, at = list(Subjective_Confinement = c(5,20))))
pairs(em)



```


```{r}

em <- summary(emmeans(mylm,~ Subjective_Confinement, at = list(Subjective_Confinement = 5:20))) %>%
  mutate(Passage_of_Time = emmean,
         LCL = lower.CL,
         UCL = upper.CL)

(p_SC <- ggplot(tostat %>%
         group_by(Subjective_Confinement) %>%
         mutate(meanPassage_of_Time = mean(Passage_of_Time),
                n = n()),
       aes(x = Subjective_Confinement, y = Passage_of_Time)) +
  geom_jitter(data = tostat, width = .1, col = 'grey') +
  geom_line(data = em) +
  # geom_point(col='green',data = em2) +
  geom_ribbon(mapping = aes(ymin = LCL, ymax = UCL),col = NA, alpha = .2,data = em) +
  geom_point(aes(y = meanPassage_of_Time, size = n/5), col = 'black', show.legend = F) +
    xlab('Subjective Confinement') +
    ylab('Passage of Time')
# +
#   geom_label(aes(y=100,label = n))
)
```
```{r}

em <- summary(emmeans(mylm,~ Mobility_Transit, at = list(Mobility_Transit = seq(-90,20,5)))) %>%
  mutate(Passage_of_Time = emmean,
         LCL = lower.CL,
         UCL = upper.CL)

(p_MT <- ggplot(tostat %>%
         mutate(Mobility_Transit = as.numeric(as.character(cut(Mobility_Transit,breaks = seq(-90,20,5), labels = seq(-90,15,5) + 2.5)))) %>%
         group_by(Mobility_Transit) %>%
         mutate(meanPassage_of_Time = mean(Passage_of_Time),
                n = n()),
       aes(x = Mobility_Transit, y = Passage_of_Time)) +
  geom_point(data = tostat, col = 'grey') +
  geom_line(data = em) +
  # geom_point(col='green',data = em2) +
  geom_ribbon(mapping = aes(ymin = LCL, ymax = UCL),col = NA, alpha = .2,data = em) +
  geom_point(aes(y = meanPassage_of_Time, size = n), col = 'black', show.legend = F) +
    xlab('Mobility') +
    ylab('Passage of Time')
# +
#   geom_label(aes(y=100,label = n))
)
```


```{r}

em <- summary(emmeans(mylm,~ Stringency_Index, at = list(Stringency_Index = seq(35,100,5)))) %>%
  mutate(Passage_of_Time = emmean,
         LCL = lower.CL,
         UCL = upper.CL)

(p_SI <- ggplot(tostat %>%
         mutate(Stringency_Index = as.numeric(as.character(cut(Stringency_Index,breaks = seq(35,100,5), labels = seq(35,95,5) + 2.5)))) %>%
         group_by(Stringency_Index) %>%
         mutate(meanPassage_of_Time = mean(Passage_of_Time),
                n = n()),
       aes(x = Stringency_Index, y = Passage_of_Time)) +
  geom_jitter(data = tostat, width = .1, col = 'grey', alpha = .5) +
  geom_line(data = em) +
  # geom_point(col='green',data = em2) +
  geom_ribbon(mapping = aes(ymin = LCL, ymax = UCL),col = NA, alpha = .2,data = em) +
  geom_point(aes(y = meanPassage_of_Time, size = n), col = 'black', show.legend = F) +
    xlab('Stringency Index') +
    ylab('Passage of Time')
# +
#   geom_label(aes(y=100,label = n))
)
```

```{r}

em <- summary(emmeans(mylm,~ Age, at = list(Age = seq(18,88,5)))) %>%
  mutate(Passage_of_Time = emmean,
         LCL = lower.CL,
         UCL = upper.CL)

(p_A <- ggplot(tostat %>%
         mutate(Age = as.numeric(as.character(cut(Age,breaks = seq(18,83,5), labels = seq(18,78,5) + 2.5)))) %>%
         group_by(Age) %>%
         mutate(meanPassage_of_Time = mean(Passage_of_Time),
                n = n()),
       aes(x = Age, y = Passage_of_Time)) +
  geom_jitter(data = tostat, width = .1, col = 'grey', alpha = .5) +
  geom_line(data = em) +
  # geom_point(col='green',data = em2) +
  geom_ribbon(mapping = aes(ymin = LCL, ymax = UCL),col = NA, alpha = .2,data = em) +
  geom_point(aes(y = meanPassage_of_Time, size = n), col = 'black', show.legend = F) +
    xlab('Age') +
    ylab('Passage of Time')
# +
#   geom_label(aes(y=100,label = n))
)
```

```{r}

em <- summary(emmeans(mylm,~ Hour_Of_Day, at = list(Hour_Of_Day = seq(3,24)))) %>%
  mutate(Passage_of_Time = emmean,
         LCL = lower.CL,
         UCL = upper.CL)

(p_HoD <- ggplot(tostat %>%
         mutate(Hour_Of_Day = as.numeric(as.character(cut(Hour_Of_Day,breaks = seq(0,23,3), labels = seq(0,20,3) + 1.5)))) %>%
         group_by(Hour_Of_Day) %>%
         mutate(meanPassage_of_Time = mean(Passage_of_Time),
                n = n()),
       aes(x = Hour_Of_Day, y = Passage_of_Time)) +
  geom_jitter(data = tostat, width = .1, col = 'grey', alpha = .5) +
  geom_line(data = em) +
  # geom_point(col='green',data = em2) +
  geom_ribbon(mapping = aes(ymin = LCL, ymax = UCL),col = NA, alpha = .2,data = em) +
  geom_point(aes(y = meanPassage_of_Time, size = n), col = 'black', show.legend = F) +
    xlab('Hour of Day') +
    ylab('Passage of Time')
# +
#   geom_label(aes(y=100,label = n))
)
```
```{r}
library(patchwork)

p_SC
(p_MT + ylab('') + xlab('') + ggtitle('Mobility Transit') + p_SI + ylab('')+ xlab('')  + ggtitle('Stringency Index'))/ (p_A + ylab('')+ xlab('')  + ggtitle('Age') + p_HoD+ xlab('')  + ylab('') + ggtitle('Hour of Day'))
```


<!-- ## Using dichotomized values for Passage of time -->

<!-- ```{r} -->
<!-- nutostat <- tostat %>% -->
<!--   filter(Passage_of_Time != 50) %>% -->
<!--   mutate(Faster = Passage_of_Time > 50) -->

<!-- #  + Mobility_Transit + Age + Hour_Of_Day # %>% filter(!is.na(Age)) -->

<!-- m <- glm(Faster ~ Stringency_Index + Mobility_Transit + Age + Hour_Of_Day, family = 'binomial', data = nutostat) -->
<!-- plot(m) -->
<!-- summary(m) -->
<!-- anova(m, test = 'F') -->

<!-- ``` -->

