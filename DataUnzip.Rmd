---
title: "Data Unzip"
output:
  html_document:
    code_folding: hide
    df_print: paged
    toc: yes
  html_notebook:
    code_folding: hide
    df_print: paged
    toc: yes
params:
  experimentID: 16095
  rootdir: '/home/maximilien.chaumon/ownCloud/Lab/00-Projects/TimeSocialDistancing/DATA'
---

```{r, message=F}
library(tidyverse)
source('helpers.R')
```

### list zip files

```{r, message=F}
eid <- as.numeric(params$experimentID)
zipfiles <- unlist(sapply(params$experimentID,function(f){list.files(params$rootdir,paste0('data_exp_',f,'-v.*.zip'),full.names = T)}))

tmpdir <- file.path(params$rootdir,'.tmp')

```

This document shows the output of data extraction and merge for files ``r basename(zipfiles)``

### Unzip data

```{r}

unlink(tmpdir,recursive=T)
dum <- sapply(zipfiles,function(x){unzip(x,exdir=tmpdir)})

```

We just unzipped data from experiment ``r params$experimentID`` to a temporary folder.

### Rename files

We retrieve unique task identifiers: column `3` "Gorilla Protocol names" from [this google sheet](https://docs.google.com/spreadsheets/d/1Mwy2aGCJ6vSpp4a32NOs83e2H73MQRFUOL_193yb8sQ/edit#gid=0), based on expermient ID (i.e. language) retrieved from [this google sheet]('https://docs.google.com/spreadsheets/d/1p6_WHQXNGFw2EJGny1jb5qivMy2pJ_VRRYoDGRLxgbY/edit#gid=0').

```{r}

# output directory is the zip filename plus experiment name

datadir <- file.path(params$rootdir,paste0('data_exp_', paste(as.character(params$experimentID),collapse = '-'), '_', ExperimentName[1]))

# remove eventual previous output in that directory
unlink(datadir,recursive=T)

```

Now that we have these, we know that the current data comes from experiment ``r params$experimentID``  (``r ExperimentName``). We can rename all files using `UniqueName` values from [this google sheet](https://docs.google.com/spreadsheets/d/1Mwy2aGCJ6vSpp4a32NOs83e2H73MQRFUOL_193yb8sQ/edit#gid=0).


**The text below shows eventual missing data. Check if the nodes below need to be present in [this google sheet](https://docs.google.com/spreadsheets/d/1Mwy2aGCJ6vSpp4a32NOs83e2H73MQRFUOL_193yb8sQ/edit#gid=0)**

```{r,warning=F}
fs <- list.files(tmpdir,full.names = T,recursive = T)
dir.create(datadir)

for (f in fs) {
  d <- switch(tools::file_ext(f),
              csv = read_csv(f,col_types = cols()),
              xlsx = readxl::read_excel(f)) %>%
    filter(!is.na(`Task Name`))
  # print(f)
  
  if (nrow(d) == 0) {
    # cat(paste('No data for', basename(f)),sep='\n')
    file.remove(f)
    next
  }
  
  CurrNode <- filter(allnodes,get(ExperimentName) == gsub('.*-([[:alnum:]]{4})','\\1',unique(d$`Tree Node Key`)))
  
  if (nrow(CurrNode) == 0 ){
    cat(paste('Could not locate task for',basename(f), ':', unique(d$`Task Name`)),sep='\n')
    file.remove(f)
    next
  }
  
  write_csv(d, path = file.path(datadir, paste0(CurrNode$UniqueName, '_v-', unique(d$`Experiment Version`), '.csv')))
  
  file.remove(f)
}

```

### Merge experiment versions

**Output files created:**

```{r,message=F}
fs <- list.files(datadir,pattern='([^\\/]*)_v-(.*).csv',full.names = T) %>%
  tibble(fname=.) %>%
  extract(fname,into=c('UniqueName','Experiment Version'),'([^\\/]*)_v-(.*).csv',remove = F) %>%
  group_by(UniqueName) %>%
  group_split()


for (f in fs) {
  fn <- unique(f$UniqueName)
  d <- plyr::ldply(as.list(f$fname),read_csv) %>%
    bind_rows() %>%
    arrange(`Experiment Version`)
  write_csv(d, path = file.path(datadir, paste0(fn,'.csv')))
  cat(paste0(fn,'.csv'),sep='\n')
  file.remove(f$fname)
}
```

### output different column names to a table

Storing the results in `ColumnNames.csv`

```{r}

fs <- list.files(datadir,pattern='([^\\/]*).csv',full.names = T) %>%
  tibble(fname=.) %>%
  extract(fname,into=c('UniqueName'),'([^\\/]*).csv',remove = F) %>%
  group_by(UniqueName) %>%
  group_split()

d <- tibble()
for (f in fs) {
  # get column names into a column
  # print(f)
  d <- read_csv(f$fname, col_types = cols(), n_max = 1) %>%
    colnames() %>%
    tibble(Column = .) %>%
    mutate(experimentID = paste(params$experimentID,collapse='-'),
           UniqueName = f$UniqueName,
           ColNum = 1:nrow(.)) %>%
    bind_rows(d)
}

extraColumnNames <- d %>% filter(!ColNum %in% seq(1,26),
             !str_detect(Column,'(order|checkpoint|branch)'))
ColumnNames <- d %>%
  pivot_wider(values_from = c('Column'),names_from = c('experimentID','UniqueName'),values_fn = list(Column = first))

write_csv(ColumnNames,file.path(datadir,'ColumnNames.csv'),na = '')
(ColumnNames)
```

```{r}

if ( !file.exists(f <- file.path(datadir,'..','extraColumnNames.csv'))){
  allColumnNames <- extraColumnNames %>%
    write_csv(f)
} else {
  # read all colum names in all seen experiments so far
  allColumnNames <- read_csv(file = f,col_types = cols()) %>%
    mutate(experimentID = as.character(experimentID)) %>%
    # if experimentID exists already, update with current ColumnNames
    filter( experimentID != paste(params$experimentID,collapse='-')) %>%
    bind_rows(extraColumnNames) %>%
    write_csv(f)
}

# allColumnNames %>%
#   group_by(ColNum,UniqueName) %>%
#   summarize(n = n()) %>%
#   ungroup() %>%
#   summarize(`NExperiments` = unique(n))

```


### For questionnaires, list question names

Storing the results in `QuestionKeys.csv`

```{r, warning=F}
fs <- list.files(datadir,pattern='(S[^\\/]*).csv',full.names = T) %>%
  tibble(fname=.) %>%
  extract(fname,into=c('UniqueName'),'([^\\/]*).csv',remove = F) %>%
  group_by(UniqueName) %>%
  group_split()


d <- tibble()
for (f in fs) {
  # get column names into a column
  # print(f)
  tmp <- read_csv(f$fname, col_types = cols())
  if (startsWith(unique(tmp$`Tree Node Key`),'task')) next
  
  d <- tibble(Question = unique(tmp$`Question Key`)) %>%
    mutate(experimentID = paste(params$experimentID,collapse = '-'),
           UniqueName = f$UniqueName,
           KeyNum = 1:nrow(.)) %>%
    bind_rows(d)
  
}

QuestionKeys <- d %>%
  pivot_wider(values_from = c('Question'),names_from = c('experimentID','UniqueName'),values_fn = list(Column = first))
write_csv(QuestionKeys,file.path(datadir,'QuestionKeys.csv'),na = '')
(QuestionKeys)

```



